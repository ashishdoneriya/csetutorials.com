<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>BigData on Cse Tutorials</title><link>https://csetutorials.com/topics/bigdata/</link><description>Recent content in BigData on Cse Tutorials</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 15 Jul 2025 10:00:00 +0530</lastBuildDate><atom:link href="https://csetutorials.com/topics/bigdata/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Spark: Core Concepts and Execution Flow</title><link>https://csetutorials.com/spark-core-concepts-and-execution-flow.html.html</link><pubDate>Tue, 15 Jul 2025 10:00:00 +0530</pubDate><guid>https://csetutorials.com/spark-core-concepts-and-execution-flow.html.html</guid><description>&lt;p>Apache Spark is a computing system used for processing very large amounts of data quickly by distributing the work across a cluster of many computers.&lt;/p>
&lt;h2 id="1-fundamental-concepts">1. Fundamental Concepts&lt;/h2>
&lt;h3 id="the-distributed-dataset-and-partitions">The Distributed Dataset and Partitions&lt;/h3>
&lt;p>Spark is designed to process datasets that are too large for one machine. To do this, it must divide the large dataset into smaller chunks that can be processed in parallel. Each of these chunks is called a Partition.&lt;/p></description></item></channel></rss>